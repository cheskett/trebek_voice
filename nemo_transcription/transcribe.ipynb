{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribe Demo\n",
    "\n",
    "Start by loading nemo models. The first nemo model is for transcription and the second for restoring punctuation and capitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "nemo_asr.models.EncDecRNNTBPEModel.list_available_models()\n",
    "asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(\"nvidia/stt_en_conformer_transducer_xlarge\")\n",
    "punc_model = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(model_name=\"punctuation_en_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5dbb428ed74949b77cae4d09166b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"well i don't wish to see it any more observed phoebe turning away her eyes it is certainly very like the old portrait\"]\n",
      "[NeMo I 2022-12-24 08:54:20 punctuation_capitalization_model:1153] Using batch size 1 for inference\n",
      "[NeMo I 2022-12-24 08:54:20 punctuation_capitalization_infer_dataset:123] Max length: 27\n",
      "[NeMo I 2022-12-24 08:54:20 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-12-24 08:54:20 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2022-12-24 08:54:20 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2022-12-24 08:54:20 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 18.04batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_ids:\n",
      " tensor([[  101,  2092,  1045,  2123,  1005,  1056,  4299,  2000,  2156,  2009,\n",
      "          2151,  2062,  5159, 18188,  3810,  2185,  2014,  2159,  2009,  2003,\n",
      "          5121,  2200,  2066,  1996,  2214,  6533,   102]]) inp_type_ids:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]) inp_mask:\n",
      " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "punct_logits:\n",
      " tensor([[[ 4.8503, -2.9812, -0.4151, -2.8845],\n",
      "         [ 0.1323,  3.0063, -1.4942, -2.4208],\n",
      "         [ 6.8541, -2.1068, -2.5900, -2.8318],\n",
      "         [ 6.9369, -1.6710, -2.7945, -2.7861],\n",
      "         [ 0.7901, -0.5896,  0.4698, -0.4055],\n",
      "         [ 6.9584, -1.7214, -2.7256, -2.7364],\n",
      "         [ 6.7784, -1.6331, -2.5843, -2.7147],\n",
      "         [ 7.0229, -1.9993, -2.6366, -2.6633],\n",
      "         [ 6.8360, -1.8749, -2.5989, -2.7527],\n",
      "         [ 5.7690, -0.9293, -2.3619, -3.0327],\n",
      "         [ 6.3577, -1.5796, -2.2574, -3.0103],\n",
      "         [-0.8526,  2.3200,  0.7600, -1.8296],\n",
      "         [ 4.6161, -0.1848, -1.7661, -3.1371],\n",
      "         [-0.3385,  2.0545,  0.4572, -2.3048],\n",
      "         [ 6.2461, -1.5372, -2.1920, -3.1027],\n",
      "         [ 4.3077, -0.0943, -1.6392, -2.8859],\n",
      "         [ 6.5397, -1.9700, -2.4342, -3.0442],\n",
      "         [-1.5846,  0.8726,  2.7737, -2.2393],\n",
      "         [ 6.0563, -1.3304, -2.4704, -3.0900],\n",
      "         [ 4.3906,  0.3843, -2.6281, -3.1484],\n",
      "         [ 4.8109,  0.7962, -2.8796, -3.4941],\n",
      "         [ 6.2766, -0.6440, -2.7775, -3.3631],\n",
      "         [ 6.3707, -1.1274, -2.3198, -3.1027],\n",
      "         [ 7.3957, -2.1847, -2.7468, -2.9096],\n",
      "         [ 7.2297, -1.7562, -2.7376, -3.3547],\n",
      "         [-1.5793, -3.3176,  6.7130, -1.0783],\n",
      "         [ 0.4122, -0.6935,  0.7825, -0.2087]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>) capit_logits:\n",
      " tensor([[[ 2.3287, -2.1349],\n",
      "         [-3.6766,  3.4086],\n",
      "         [-3.5310,  3.5647],\n",
      "         [ 4.0394, -4.6172],\n",
      "         [ 0.3615,  0.0173],\n",
      "         [ 4.1204, -4.6621],\n",
      "         [ 4.3980, -4.9527],\n",
      "         [ 4.2219, -4.7024],\n",
      "         [ 4.0632, -4.4815],\n",
      "         [ 3.9394, -4.2363],\n",
      "         [ 3.7662, -3.6879],\n",
      "         [ 3.6218, -3.7308],\n",
      "         [ 1.8869, -1.3813],\n",
      "         [-1.8447,  2.1886],\n",
      "         [ 1.8307, -1.3843],\n",
      "         [ 4.0541, -4.1429],\n",
      "         [ 3.3658, -3.3607],\n",
      "         [ 3.2469, -3.1011],\n",
      "         [-1.3369,  1.1413],\n",
      "         [ 3.0636, -3.5428],\n",
      "         [ 3.6889, -4.1819],\n",
      "         [ 4.1809, -4.5973],\n",
      "         [ 4.3084, -4.7676],\n",
      "         [ 3.7210, -4.0429],\n",
      "         [ 3.2180, -3.3306],\n",
      "         [ 3.7427, -2.9151],\n",
      "         [ 0.1438,  0.3159]]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "Well, I don't wish to see it any more, observed Phoebe, turning away her eyes. It is certainly very like the old portrait.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = asr_model.transcribe(['wavs/2086-149220-0033.wav'])\n",
    "print(text[0])\n",
    "punc_text = punc_model.add_punctuation_capitalization(text[0])\n",
    "print(punc_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-24 08:35:50 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
      "[NeMo I 2022-12-24 08:35:50 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo\n",
      "[NeMo I 2022-12-24 08:35:50 common:911] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-12-24 08:35:52 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmpduuhpz_b/tokenizer.vocab_file, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-12-24 08:35:54 modelPT:222] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-24 08:35:54 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-12-24 08:35:54 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-12-24 08:35:54 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-12-24 08:35:57 punctuation_capitalization_model:705] The artifact `class_labels.punct_labels_file` was not found in checkpoint. Will rely on `punct_label_ids` parameter\n",
      "[NeMo W 2022-12-24 08:35:57 punctuation_capitalization_model:727] The artifact `class_labels.capit_labels_file` was not found in checkpoint. Will rely on `capit_label_ids` parameter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-24 08:35:57 save_restore_connector:243] Model PunctuationCapitalizationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
      "[NeMo I 2022-12-24 08:35:57 punctuation_capitalization_model:1153] Using batch size 1 for inference\n",
      "[NeMo I 2022-12-24 08:35:57 punctuation_capitalization_infer_dataset:123] Max length: 27\n",
      "[NeMo I 2022-12-24 08:35:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-12-24 08:35:57 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2022-12-24 08:35:57 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2022-12-24 08:35:57 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.99batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_ids:\n",
      " tensor([[  101,  2002,  2097,  3637,  6229, 11501,  2021,  2077,  2009,  1005,\n",
      "          1055,  2601,  2002,  1005,  2222,  2031,  2296, 12695, 10810,  2008,\n",
      "          1005,  1055,  1999, 20919,  9221,  2380,   102]]) inp_type_ids:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]) inp_mask:\n",
      " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "punct_logits:\n",
      " tensor([[[ 6.0038, -2.5931, -0.5617, -3.7318],\n",
      "         [ 6.8852, -2.2081, -2.7300, -2.6337],\n",
      "         [ 6.7950, -1.3456, -2.9009, -2.6717],\n",
      "         [ 6.5351, -0.9809, -2.9165, -2.8146],\n",
      "         [ 7.0712, -1.2897, -3.0332, -2.8454],\n",
      "         [ 2.0359,  3.7379, -1.7103, -4.1689],\n",
      "         [ 5.6519,  0.2897, -2.8706, -3.8278],\n",
      "         [ 6.7520, -1.1492, -2.9665, -2.8356],\n",
      "         [ 7.0598, -1.7922, -2.9366, -2.6153],\n",
      "         [ 7.0001, -1.7423, -2.8704, -2.5851],\n",
      "         [ 7.0212, -1.7382, -2.9004, -2.5412],\n",
      "         [ 2.5520,  2.6577, -1.7741, -3.9264],\n",
      "         [ 7.2337, -1.7373, -3.1294, -3.0290],\n",
      "         [ 0.8801, -0.5484,  0.6423, -0.4063],\n",
      "         [ 6.9593, -1.6972, -2.8423, -2.5519],\n",
      "         [ 7.0089, -1.7941, -2.7252, -2.6158],\n",
      "         [ 7.1240, -1.5641, -2.8538, -2.7286],\n",
      "         [ 7.3060, -1.7672, -2.9825, -2.8119],\n",
      "         [ 5.6480,  0.1198, -2.7241, -3.1778],\n",
      "         [ 7.3325, -1.8142, -2.9071, -2.8133],\n",
      "         [ 7.1590, -1.8195, -2.7849, -2.6138],\n",
      "         [ 7.0819, -1.5759, -2.8897, -2.5982],\n",
      "         [ 6.8835, -1.3688, -2.6895, -2.7277],\n",
      "         [ 6.7223, -0.8443, -2.9839, -3.7138],\n",
      "         [ 7.1457, -1.0601, -2.8367, -4.0080],\n",
      "         [-1.8698, -2.7225,  7.3282, -1.7332],\n",
      "         [ 0.7623, -0.6333,  0.8074, -0.3524]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>) capit_logits:\n",
      " tensor([[[ 2.5261, -2.6398],\n",
      "         [-4.2646,  4.2512],\n",
      "         [ 4.4560, -5.2579],\n",
      "         [ 4.4827, -5.3013],\n",
      "         [ 4.1371, -4.7951],\n",
      "         [ 3.3717, -3.8017],\n",
      "         [ 2.8614, -2.9198],\n",
      "         [ 4.2260, -5.0396],\n",
      "         [ 4.3116, -5.0188],\n",
      "         [ 4.3767, -5.0368],\n",
      "         [ 4.3916, -5.0747],\n",
      "         [ 4.0605, -4.5607],\n",
      "         [ 3.4828, -4.3027],\n",
      "         [ 0.1832,  0.2999],\n",
      "         [ 4.3906, -5.1867],\n",
      "         [ 4.3585, -5.1678],\n",
      "         [ 4.0205, -4.8484],\n",
      "         [ 3.8359, -4.5562],\n",
      "         [ 4.1745, -5.0140],\n",
      "         [ 3.8395, -4.4144],\n",
      "         [ 4.2521, -4.9099],\n",
      "         [ 4.2970, -5.0224],\n",
      "         [ 4.3809, -5.0824],\n",
      "         [-2.3343,  2.5298],\n",
      "         [-1.3939,  1.6265],\n",
      "         [-0.8962,  1.5378],\n",
      "         [ 0.0473,  0.4517]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"He will sleep till noon, but before it's dark, he'll have every picnic basket that's in Jellystone Park.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nemo.collections.nlp as nemo_nlp\n",
    "punc_model = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(model_name=\"punctuation_en_bert\")\n",
    "punc_model.add_punctuation_capitalization(['he will sleep till noon but before it\\'s dark he\\'ll have every picnic basket that\\'s in jellystone park'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_arch_list()\n",
    "torch.cuda.get_device_properties(0)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Clara and I live in Berkeley, California. Ist das eine Frage, Frau Müller?\n"
     ]
    }
   ],
   "source": [
    "text = \"My name is Clara and I live in Berkeley California Ist das eine Frage Frau Müller\"\n",
    "result = model.restore_punctuation(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
