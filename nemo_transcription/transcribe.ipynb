{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-24 08:37:38 mixins:170] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-12-24 08:37:39 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath:\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket1/tarred_audio_manifest.json\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket2/tarred_audio_manifest.json\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket3/tarred_audio_manifest.json\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket4/tarred_audio_manifest.json\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket5/tarred_audio_manifest.json\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket6/tarred_audio_manifest.json\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket7/tarred_audio_manifest.json\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket8/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: true\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket1/audio__OP_0..8191_CL_.tar\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket2/audio__OP_0..8191_CL_.tar\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket3/audio__OP_0..8191_CL_.tar\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket4/audio__OP_0..8191_CL_.tar\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket5/audio__OP_0..8191_CL_.tar\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket6/audio__OP_0..8191_CL_.tar\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket7/audio__OP_0..8191_CL_.tar\n",
      "    - - /data/NeMo_ASR_SET/English/v3.0/train_bucketed/bucket8/audio__OP_0..8191_CL_.tar\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size:\n",
      "    - 32\n",
      "    - 32\n",
      "    - 16\n",
      "    - 16\n",
      "    - 16\n",
      "    - 16\n",
      "    - 8\n",
      "    - 8\n",
      "    \n",
      "[NeMo W 2022-12-24 08:37:39 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath:\n",
      "    - /data/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 4\n",
      "    shuffle: false\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    min_duration: 0\n",
      "    \n",
      "[NeMo W 2022-12-24 08:37:39 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath:\n",
      "    - /data/librispeech_withsp2/manifests/librivox-test-other.json\n",
      "    - /data/librispeech_withsp2/manifests/librivox-dev-clean.json\n",
      "    - /data/librispeech_withsp2/manifests/librivox-dev-other.json\n",
      "    - /data/librispeech_withsp2/manifests/librivox-test-clean.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 4\n",
      "    shuffle: false\n",
      "    num_workers: 4\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: na\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-24 08:37:39 features:225] PADDING: 0\n",
      "[NeMo I 2022-12-24 08:37:43 rnnt_models:207] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2022-12-24 08:37:50 save_restore_connector:243] Model EncDecRNNTBPEModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--stt_en_conformer_transducer_xlarge/snapshots/96472b7552a5d0559a22399ea300498c5412699f/stt_en_conformer_transducer_xlarge.nemo.\n",
      "[NeMo I 2022-12-24 08:37:50 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
      "[NeMo I 2022-12-24 08:37:50 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo\n",
      "[NeMo I 2022-12-24 08:37:50 common:911] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-12-24 08:37:52 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmp2j721cdc/tokenizer.vocab_file, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-12-24 08:37:54 modelPT:222] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-24 08:37:54 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-12-24 08:37:54 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-12-24 08:37:54 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-12-24 08:37:57 punctuation_capitalization_model:705] The artifact `class_labels.punct_labels_file` was not found in checkpoint. Will rely on `punct_label_ids` parameter\n",
      "[NeMo W 2022-12-24 08:37:57 punctuation_capitalization_model:727] The artifact `class_labels.capit_labels_file` was not found in checkpoint. Will rely on `capit_label_ids` parameter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-24 08:37:57 save_restore_connector:243] Model PunctuationCapitalizationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "nemo_asr.models.EncDecRNNTBPEModel.list_available_models()\n",
    "asr_model = nemo_asr.models.EncDecRNNTBPEModel.from_pretrained(\"nvidia/stt_en_conformer_transducer_xlarge\")\n",
    "punc_model = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(model_name=\"punctuation_en_bert\")\n",
    "\n",
    "# asr_model.transcribe(['wavs/jp_apr_2004_4_mono.wav'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.nlp.models import PunctuationCapitalizationLexicalAudioModel\n",
    "\n",
    "# to get the list of pre-trained models\n",
    "PunctuationCapitalizationLexicalAudioModel.list_available_models()\n",
    "\n",
    "# Download and load the pre-trained model\n",
    "model = PunctuationCapitalizationLexicalAudioModel.from_pretrained(\"nvidia/stt_en_conformer_ctc_medium\")\n",
    "\n",
    "# try the model on a few examples\n",
    "# model.add_punctuation_capitalization(['how are you', 'great how about you'], audio_queries=['/path/to/1.wav', '/path/to/2.wav'], target_sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dldata-public.s3.us-east-2.amazonaws.com/2086-149220-0033.wav\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f79bd0125f441bf99d4b0e0d718bb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"he will sleep till noon but before it's dark he'll have every picnic basket that's in jellystone park\"]\n",
      "[NeMo I 2022-12-24 08:43:56 punctuation_capitalization_model:1153] Using batch size 1 for inference\n",
      "[NeMo I 2022-12-24 08:43:56 punctuation_capitalization_infer_dataset:123] Max length: 27\n",
      "[NeMo I 2022-12-24 08:43:56 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-12-24 08:43:56 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2022-12-24 08:43:56 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2022-12-24 08:43:56 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 17.29batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_ids:\n",
      " tensor([[  101,  2002,  2097,  3637,  6229, 11501,  2021,  2077,  2009,  1005,\n",
      "          1055,  2601,  2002,  1005,  2222,  2031,  2296, 12695, 10810,  2008,\n",
      "          1005,  1055,  1999, 20919,  9221,  2380,   102]]) inp_type_ids:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]) inp_mask:\n",
      " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "punct_logits:\n",
      " tensor([[[ 6.0038, -2.5931, -0.5617, -3.7318],\n",
      "         [ 6.8852, -2.2081, -2.7300, -2.6337],\n",
      "         [ 6.7950, -1.3456, -2.9009, -2.6717],\n",
      "         [ 6.5351, -0.9809, -2.9165, -2.8146],\n",
      "         [ 7.0712, -1.2897, -3.0332, -2.8454],\n",
      "         [ 2.0359,  3.7379, -1.7103, -4.1689],\n",
      "         [ 5.6519,  0.2897, -2.8706, -3.8278],\n",
      "         [ 6.7520, -1.1492, -2.9665, -2.8356],\n",
      "         [ 7.0598, -1.7922, -2.9366, -2.6153],\n",
      "         [ 7.0001, -1.7423, -2.8704, -2.5851],\n",
      "         [ 7.0212, -1.7382, -2.9004, -2.5412],\n",
      "         [ 2.5520,  2.6577, -1.7741, -3.9264],\n",
      "         [ 7.2337, -1.7373, -3.1294, -3.0290],\n",
      "         [ 0.8801, -0.5484,  0.6423, -0.4063],\n",
      "         [ 6.9593, -1.6972, -2.8423, -2.5519],\n",
      "         [ 7.0089, -1.7941, -2.7252, -2.6158],\n",
      "         [ 7.1240, -1.5641, -2.8538, -2.7286],\n",
      "         [ 7.3060, -1.7672, -2.9825, -2.8119],\n",
      "         [ 5.6480,  0.1198, -2.7241, -3.1778],\n",
      "         [ 7.3325, -1.8142, -2.9071, -2.8133],\n",
      "         [ 7.1590, -1.8195, -2.7849, -2.6138],\n",
      "         [ 7.0819, -1.5759, -2.8897, -2.5982],\n",
      "         [ 6.8835, -1.3688, -2.6895, -2.7277],\n",
      "         [ 6.7223, -0.8443, -2.9839, -3.7138],\n",
      "         [ 7.1457, -1.0601, -2.8367, -4.0080],\n",
      "         [-1.8698, -2.7225,  7.3282, -1.7332],\n",
      "         [ 0.7623, -0.6333,  0.8074, -0.3524]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>) capit_logits:\n",
      " tensor([[[ 2.5261, -2.6398],\n",
      "         [-4.2646,  4.2512],\n",
      "         [ 4.4560, -5.2579],\n",
      "         [ 4.4827, -5.3013],\n",
      "         [ 4.1371, -4.7951],\n",
      "         [ 3.3717, -3.8017],\n",
      "         [ 2.8614, -2.9198],\n",
      "         [ 4.2260, -5.0396],\n",
      "         [ 4.3116, -5.0188],\n",
      "         [ 4.3767, -5.0368],\n",
      "         [ 4.3916, -5.0747],\n",
      "         [ 4.0605, -4.5607],\n",
      "         [ 3.4828, -4.3027],\n",
      "         [ 0.1832,  0.2999],\n",
      "         [ 4.3906, -5.1867],\n",
      "         [ 4.3585, -5.1678],\n",
      "         [ 4.0205, -4.8484],\n",
      "         [ 3.8359, -4.5562],\n",
      "         [ 4.1745, -5.0140],\n",
      "         [ 3.8395, -4.4144],\n",
      "         [ 4.2521, -4.9099],\n",
      "         [ 4.2970, -5.0224],\n",
      "         [ 4.3809, -5.0824],\n",
      "         [-2.3343,  2.5298],\n",
      "         [-1.3939,  1.6265],\n",
      "         [-0.8962,  1.5378],\n",
      "         [ 0.0473,  0.4517]]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "He will sleep till noon, but before it's dark, he'll have every picnic basket that's in Jellystone Park.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = asr_model.transcribe(['wavs/jp_apr_2004_4_mono.wav'])\n",
    "print(text[0])\n",
    "punc_text = punc_model.add_punctuation_capitalization(text[0])\n",
    "print(punc_text[0])\n",
    "\n",
    "\n",
    "# .encode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-24 08:35:50 cloud:56] Found existing object /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
      "[NeMo I 2022-12-24 08:35:50 cloud:62] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo\n",
      "[NeMo I 2022-12-24 08:35:50 common:911] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-12-24 08:35:52 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: bert-base-uncased, vocab_file: /tmp/tmpduuhpz_b/tokenizer.vocab_file, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-12-24 08:35:54 modelPT:222] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-12-24 08:35:54 modelPT:142] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-12-24 08:35:54 modelPT:149] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-12-24 08:35:54 modelPT:155] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_audio: false\n",
      "    audio_file: null\n",
      "    sample_rate: 16000\n",
      "    use_bucketing: true\n",
      "    batch_size: 32\n",
      "    preload_audios: true\n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shard_strategy: scatter\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertEncoder: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-12-24 08:35:57 punctuation_capitalization_model:705] The artifact `class_labels.punct_labels_file` was not found in checkpoint. Will rely on `punct_label_ids` parameter\n",
      "[NeMo W 2022-12-24 08:35:57 punctuation_capitalization_model:727] The artifact `class_labels.capit_labels_file` was not found in checkpoint. Will rely on `capit_label_ids` parameter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-12-24 08:35:57 save_restore_connector:243] Model PunctuationCapitalizationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.13.0/punctuation_en_bert/93b0369b5e0d147f61895feffcbcfb88/punctuation_en_bert.nemo.\n",
      "[NeMo I 2022-12-24 08:35:57 punctuation_capitalization_model:1153] Using batch size 1 for inference\n",
      "[NeMo I 2022-12-24 08:35:57 punctuation_capitalization_infer_dataset:123] Max length: 27\n",
      "[NeMo I 2022-12-24 08:35:57 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-12-24 08:35:57 data_preprocessing:406] Min: 25 |                  Max: 25 |                  Mean: 25.0 |                  Median: 25.0\n",
      "[NeMo I 2022-12-24 08:35:57 data_preprocessing:412] 75 percentile: 25.00\n",
      "[NeMo I 2022-12-24 08:35:57 data_preprocessing:413] 99 percentile: 25.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.99batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_ids:\n",
      " tensor([[  101,  2002,  2097,  3637,  6229, 11501,  2021,  2077,  2009,  1005,\n",
      "          1055,  2601,  2002,  1005,  2222,  2031,  2296, 12695, 10810,  2008,\n",
      "          1005,  1055,  1999, 20919,  9221,  2380,   102]]) inp_type_ids:\n",
      " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0]]) inp_mask:\n",
      " tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "punct_logits:\n",
      " tensor([[[ 6.0038, -2.5931, -0.5617, -3.7318],\n",
      "         [ 6.8852, -2.2081, -2.7300, -2.6337],\n",
      "         [ 6.7950, -1.3456, -2.9009, -2.6717],\n",
      "         [ 6.5351, -0.9809, -2.9165, -2.8146],\n",
      "         [ 7.0712, -1.2897, -3.0332, -2.8454],\n",
      "         [ 2.0359,  3.7379, -1.7103, -4.1689],\n",
      "         [ 5.6519,  0.2897, -2.8706, -3.8278],\n",
      "         [ 6.7520, -1.1492, -2.9665, -2.8356],\n",
      "         [ 7.0598, -1.7922, -2.9366, -2.6153],\n",
      "         [ 7.0001, -1.7423, -2.8704, -2.5851],\n",
      "         [ 7.0212, -1.7382, -2.9004, -2.5412],\n",
      "         [ 2.5520,  2.6577, -1.7741, -3.9264],\n",
      "         [ 7.2337, -1.7373, -3.1294, -3.0290],\n",
      "         [ 0.8801, -0.5484,  0.6423, -0.4063],\n",
      "         [ 6.9593, -1.6972, -2.8423, -2.5519],\n",
      "         [ 7.0089, -1.7941, -2.7252, -2.6158],\n",
      "         [ 7.1240, -1.5641, -2.8538, -2.7286],\n",
      "         [ 7.3060, -1.7672, -2.9825, -2.8119],\n",
      "         [ 5.6480,  0.1198, -2.7241, -3.1778],\n",
      "         [ 7.3325, -1.8142, -2.9071, -2.8133],\n",
      "         [ 7.1590, -1.8195, -2.7849, -2.6138],\n",
      "         [ 7.0819, -1.5759, -2.8897, -2.5982],\n",
      "         [ 6.8835, -1.3688, -2.6895, -2.7277],\n",
      "         [ 6.7223, -0.8443, -2.9839, -3.7138],\n",
      "         [ 7.1457, -1.0601, -2.8367, -4.0080],\n",
      "         [-1.8698, -2.7225,  7.3282, -1.7332],\n",
      "         [ 0.7623, -0.6333,  0.8074, -0.3524]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>) capit_logits:\n",
      " tensor([[[ 2.5261, -2.6398],\n",
      "         [-4.2646,  4.2512],\n",
      "         [ 4.4560, -5.2579],\n",
      "         [ 4.4827, -5.3013],\n",
      "         [ 4.1371, -4.7951],\n",
      "         [ 3.3717, -3.8017],\n",
      "         [ 2.8614, -2.9198],\n",
      "         [ 4.2260, -5.0396],\n",
      "         [ 4.3116, -5.0188],\n",
      "         [ 4.3767, -5.0368],\n",
      "         [ 4.3916, -5.0747],\n",
      "         [ 4.0605, -4.5607],\n",
      "         [ 3.4828, -4.3027],\n",
      "         [ 0.1832,  0.2999],\n",
      "         [ 4.3906, -5.1867],\n",
      "         [ 4.3585, -5.1678],\n",
      "         [ 4.0205, -4.8484],\n",
      "         [ 3.8359, -4.5562],\n",
      "         [ 4.1745, -5.0140],\n",
      "         [ 3.8395, -4.4144],\n",
      "         [ 4.2521, -4.9099],\n",
      "         [ 4.2970, -5.0224],\n",
      "         [ 4.3809, -5.0824],\n",
      "         [-2.3343,  2.5298],\n",
      "         [-1.3939,  1.6265],\n",
      "         [-0.8962,  1.5378],\n",
      "         [ 0.0473,  0.4517]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"He will sleep till noon, but before it's dark, he'll have every picnic basket that's in Jellystone Park.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nemo.collections.nlp as nemo_nlp\n",
    "punc_model = nemo_nlp.models.PunctuationCapitalizationModel.from_pretrained(model_name=\"punctuation_en_bert\")\n",
    "punc_model.add_punctuation_capitalization(['he will sleep till noon but before it\\'s dark he\\'ll have every picnic basket that\\'s in jellystone park'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_arch_list()\n",
    "torch.cuda.get_device_properties(0)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Clara and I live in Berkeley, California. Ist das eine Frage, Frau Müller?\n"
     ]
    }
   ],
   "source": [
    "text = \"My name is Clara and I live in Berkeley California Ist das eine Frage Frau Müller\"\n",
    "result = model.restore_punctuation(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
